{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-21 16:28:29.161395: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-04-21 16:28:29.789720: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fashion MNIST Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = \"Fashion\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting Up Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "fashion_mnist = tf.keras.datasets.fashion_mnist.load_data()\n",
    "(X_train_full, y_train_full), (X_test, y_test) = fashion_mnist\n",
    "X_train, y_train = X_train_full[:-5000], y_train_full[:-5000]\n",
    "X_valid, y_valid = X_train_full[-5000:], y_train_full[-5000:]\n",
    "X_train_new = X_train.reshape(len(X_train),-1)\n",
    "X_valid_new = X_valid.reshape(len(X_valid),-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_valid, X_test = X_train / 255., X_valid / 255., X_test / 255."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = [\"T-shirt/top\",\n",
    "               \"Trouser\",\n",
    "               \"Pullover\",\n",
    "               \"Dress\",\n",
    "               \"Coat\",\n",
    "               \"Sandal\",\n",
    "               \"Shirt\",\n",
    "               \"Sneaker\",\n",
    "               \"Bag\",\n",
    "               \"Ankle boot\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Principal Component Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=28,\n",
    "          random_state=42)\n",
    "pca.fit(X_train_new)\n",
    "X_train_new = pca.transform(X_train_new)\n",
    "X_valid_new = pca.transform(X_valid_new)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyper-Parameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans_per_k = [KMeans(n_clusters=k,\n",
    "                       init=\"k-means++\",\n",
    "                       max_iter=100,\n",
    "                       n_init=10,\n",
    "                       random_state=42)\\\n",
    "                        .fit(X_train_new)\n",
    "                    for k in range(50, 1000 + 1, 50)]\n",
    "\n",
    "inertias = [model.inertia_ for model in kmeans_per_k]\n",
    "\n",
    "plt.figure(figsize=(12,4))\n",
    "plt.plot([i for i in range(50, 1000 + 1, 50)],\n",
    "         inertias,\n",
    "         \"bo-\")\n",
    "plt.xlabel(\"$k$\")\n",
    "plt.ylabel(\"Inertia\")\n",
    "plt.title(\"Inertia vs $k$\")\n",
    "plt.savefig(f\"Output/{dataset} - Inertia.png\", bbox_inches='tight', pad_inches=0)\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 450\n",
    "kmeans = KMeans(n_clusters=k,\n",
    "                n_init=10,\n",
    "                init='k-means++',\n",
    "                random_state=42)\n",
    "kmeans.fit(X_train_new)\n",
    "cluster_distance = kmeans.transform(X_train_new)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLPs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "km_old_labels = kmeans.labels_\n",
    "closest = np.argmin(cluster_distance, axis=0)\n",
    "labels = np.array([y_train[i] for i in closest])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-21 16:35:30.915265: E external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:282] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "2024-04-21 16:35:30.915294: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:134] retrieving CUDA diagnostic information for host: gpuserver\n",
      "2024-04-21 16:35:30.915300: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:141] hostname: gpuserver\n",
      "2024-04-21 16:35:30.915379: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:165] libcuda reported version is: 550.54.14\n",
      "2024-04-21 16:35:30.915398: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:169] kernel reported version is: NOT_FOUND: could not find kernel module information in driver version file contents: \"NVRM version: NVIDIA UNIX Open Kernel Module for x86_64  550.54.14  Release Build  (dvs-builder@U16-A24-2-2)  Thu Feb 22 01:44:50 UTC 2024\n",
      "GCC version:  gcc version 9.4.0 (Ubuntu 9.4.0-1ubuntu1~20.04.2) \n",
      "\"\n"
     ]
    }
   ],
   "source": [
    "tf.random.set_seed(42)\n",
    "model1 = tf.keras.Sequential()\n",
    "model1.add(tf.keras.layers.InputLayer(shape=[28, 28]))\n",
    "model1.add(tf.keras.layers.Flatten())\n",
    "model1.add(tf.keras.layers.Dense(300, activation=\"relu\"))\n",
    "model1.add(tf.keras.layers.Dense(100, activation=\"relu\"))\n",
    "model1.add(tf.keras.layers.Dense(10, activation=\"softmax\"))\n",
    "\n",
    "model1.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "               optimizer=\"sgd\",\n",
    "               metrics=[\"accuracy\"])\n",
    "\n",
    "history = model1.fit(X_train,\n",
    "                     y_train,\n",
    "                     epochs=15,\n",
    "                     verbose=0,\n",
    "                     validation_data=(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Plotting Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.294\n",
      "Loss: 0.357\n",
      "Loss: 0.894\n",
      "Loss: 0.872\n"
     ]
    }
   ],
   "source": [
    "train_loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "train_acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "epochs = list(range(1, len(train_loss) + 1))\n",
    "\n",
    "print(f'Loss: {train_loss[-1]:.3f}')\n",
    "print(f'Loss: {val_loss[-1]:.3f}')\n",
    "print(f'Loss: {train_acc[-1]:.3f}')\n",
    "print(f'Loss: {val_acc[-1]:.3f}')\n",
    "\n",
    "# Create a figure and two subplots\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 4))  # 1 row, 2 columns\n",
    "\n",
    "# Plot data on each subplot\n",
    "ax1.plot(epochs, train_acc, label=\"Training\")\n",
    "ax1.plot(epochs, val_acc, label=\"Validation\")\n",
    "ax2.plot(epochs, train_loss, label=\"Training\")\n",
    "ax2.plot(epochs, val_loss, label=\"Validation\")\n",
    "\n",
    "# Add labels and title\n",
    "ax1.set_xlabel(\"Epochs\")\n",
    "ax1.set_ylabel(\"Accuracy\")\n",
    "ax1.set_title(\"Epochs vs Accuracy\")\n",
    "ax2.set_xlabel(\"Epochs\")\n",
    "ax2.set_ylabel(\"Loss\")\n",
    "ax2.set_title(\"Epochs vs Loss\")\n",
    "\n",
    "# Add legend\n",
    "plt.legend()\n",
    "\n",
    "# Show the plot\n",
    "plt.savefig(f\"Output/{dataset} - Model 1.png\", bbox_inches='tight', pad_inches=0)\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_ri = np.array([X_train[i] for i in closest])\n",
    "y_train_ri = np.array([y_train[i] for i in closest])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(42)\n",
    "model2 = tf.keras.Sequential()\n",
    "model2.add(tf.keras.layers.InputLayer(shape=[28, 28]))\n",
    "model2.add(tf.keras.layers.Flatten())\n",
    "model2.add(tf.keras.layers.Dense(300, activation=\"relu\"))\n",
    "model2.add(tf.keras.layers.Dense(100, activation=\"relu\"))\n",
    "model2.add(tf.keras.layers.Dense(10, activation=\"softmax\"))\n",
    "\n",
    "model2.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "               optimizer=\"sgd\",\n",
    "               metrics=[\"accuracy\"])\n",
    "\n",
    "history = model2.fit(X_train_ri, \n",
    "                     y_train_ri, \n",
    "                     epochs=15,\n",
    "                     verbose=0,\n",
    "                     validation_data=(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plotting Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.774\n",
      "Loss: 0.889\n",
      "Loss: 0.778\n",
      "Loss: 0.711\n"
     ]
    }
   ],
   "source": [
    "train_loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "train_acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "epochs = list(range(1, len(train_loss) + 1))\n",
    "\n",
    "print(f'Loss: {train_loss[-1]:.3f}')\n",
    "print(f'Loss: {val_loss[-1]:.3f}')\n",
    "print(f'Loss: {train_acc[-1]:.3f}')\n",
    "print(f'Loss: {val_acc[-1]:.3f}')\n",
    "\n",
    "# Create a figure and two subplots\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 4))  # 1 row, 2 columns\n",
    "\n",
    "# Plot data on each subplot\n",
    "ax1.plot(epochs, train_acc, label=\"Training Accuracy\")\n",
    "ax1.plot(epochs, val_acc, label=\"Validation Accuracy\")\n",
    "ax2.plot(epochs, train_loss, label=\"Training Loss\")\n",
    "ax2.plot(epochs, val_loss, label=\"Validation Loss\")\n",
    "\n",
    "# Add labels and title\n",
    "ax1.set_xlabel(\"Epochs\")\n",
    "ax1.set_ylabel(\"Accuracy\")\n",
    "ax1.set_title(\"Epochs vs Accuracy\")\n",
    "ax2.set_xlabel(\"Epochs\")\n",
    "ax2.set_ylabel(\"Loss\")\n",
    "ax2.set_title(\"Epochs vs Loss\")\n",
    "\n",
    "# Add legend\n",
    "plt.legend()\n",
    "\n",
    "plt.savefig(f\"Output/{dataset} - Model 2.png\", bbox_inches='tight', pad_inches=0)\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_fp = X_train\n",
    "y_train_fp = np.empty(len(X_train_fp), dtype=np.int32)\n",
    "for i in range(0,len(X_train_fp)):\n",
    "   y_train_fp[i] = labels[km_old_labels[i]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(42)\n",
    "model3 = tf.keras.Sequential()\n",
    "model3.add(tf.keras.layers.InputLayer(shape=[28, 28]))\n",
    "model3.add(tf.keras.layers.Flatten())\n",
    "model3.add(tf.keras.layers.Dense(300, activation=\"relu\"))\n",
    "model3.add(tf.keras.layers.Dense(100, activation=\"relu\"))\n",
    "model3.add(tf.keras.layers.Dense(10, activation=\"softmax\"))\n",
    "\n",
    "model3.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "               optimizer=\"sgd\",\n",
    "               metrics=[\"accuracy\"])\n",
    "\n",
    "history = model3.fit(X_train_fp,\n",
    "                     y_train_fp,\n",
    "                     epochs=15,\n",
    "                     verbose=0,\n",
    "                     validation_data=(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plotting Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.312\n",
      "Loss: 0.659\n",
      "Loss: 0.873\n",
      "Loss: 0.787\n"
     ]
    }
   ],
   "source": [
    "train_loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "train_acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "epochs = list(range(1, len(train_loss) + 1))\n",
    "\n",
    "print(f'Loss: {train_loss[-1]:.3f}')\n",
    "print(f'Loss: {val_loss[-1]:.3f}')\n",
    "print(f'Loss: {train_acc[-1]:.3f}')\n",
    "print(f'Loss: {val_acc[-1]:.3f}')\n",
    "\n",
    "# Create a figure and two subplots\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 4))  # 1 row, 2 columns\n",
    "\n",
    "# Plot data on each subplot\n",
    "ax1.plot(epochs, train_acc, label=\"Training Accuracy\")\n",
    "ax1.plot(epochs, val_acc, label=\"Validation Accuracy\")\n",
    "ax2.plot(epochs, train_loss, label=\"Training Loss\")\n",
    "ax2.plot(epochs, val_loss, label=\"Validation Loss\")\n",
    "\n",
    "# Add labels and title\n",
    "ax1.set_xlabel(\"Epochs\")\n",
    "ax1.set_ylabel(\"Accuracy\")\n",
    "ax1.set_title(\"Epochs vs Accuracy\")\n",
    "ax2.set_xlabel(\"Epochs\")\n",
    "ax2.set_ylabel(\"Loss\")\n",
    "ax2.set_title(\"Epochs vs Loss\")\n",
    "\n",
    "# Add legend\n",
    "plt.legend()\n",
    "\n",
    "plt.savefig(f\"Output/{dataset} - Model 3.png\", bbox_inches='tight', pad_inches=0)\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_distances = cluster_distance[np.arange(len(X_train)), kmeans.labels_]\n",
    "for i in range(k):\n",
    "    in_cluster = (kmeans.labels_ == i)\n",
    "    cluster_dist = X_distances[in_cluster]\n",
    "    cutoff = np.percentile(cluster_dist, 20)\n",
    "    above_cutoff = (X_distances > cutoff)\n",
    "    X_distances[in_cluster & above_cutoff] = -1\n",
    "\n",
    "pp = (X_distances != -1)\n",
    "X_train_pp = X_train[pp]\n",
    "y_train_pp = y_train_fp[pp]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(42)\n",
    "model4 = tf.keras.Sequential()\n",
    "model4.add(tf.keras.layers.InputLayer(shape=[28, 28]))\n",
    "model4.add(tf.keras.layers.Flatten())\n",
    "model4.add(tf.keras.layers.Dense(300, activation=\"relu\"))\n",
    "model4.add(tf.keras.layers.Dense(100, activation=\"relu\"))\n",
    "model4.add(tf.keras.layers.Dense(10, activation=\"softmax\"))\n",
    "\n",
    "model4.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "               optimizer=\"sgd\",\n",
    "               metrics=[\"accuracy\"])\n",
    "\n",
    "history = model4.fit(X_train_pp,\n",
    "                     y_train_pp, \n",
    "                     epochs=15,\n",
    "                     verbose=0,\n",
    "                     validation_data=(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plotting Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.285\n",
      "Loss: 0.636\n",
      "Loss: 0.892\n",
      "Loss: 0.794\n"
     ]
    }
   ],
   "source": [
    "train_loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "train_acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "epochs = list(range(1, len(train_loss) + 1))\n",
    "\n",
    "print(f'Loss: {train_loss[-1]:.3f}')\n",
    "print(f'Loss: {val_loss[-1]:.3f}')\n",
    "print(f'Loss: {train_acc[-1]:.3f}')\n",
    "print(f'Loss: {val_acc[-1]:.3f}')\n",
    "\n",
    "# Create a figure and two subplots\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 4))  # 1 row, 2 columns\n",
    "\n",
    "# Plot data on each subplot\n",
    "ax1.plot(epochs, train_acc, label=\"Training Accuracy\")\n",
    "ax1.plot(epochs, val_acc, label=\"Validation Accuracy\")\n",
    "ax2.plot(epochs, train_loss, label=\"Training Loss\")\n",
    "ax2.plot(epochs, val_loss, label=\"Validation Loss\")\n",
    "\n",
    "# Add labels and title\n",
    "ax1.set_xlabel(\"Epochs\")\n",
    "ax1.set_ylabel(\"Accuracy\")\n",
    "ax1.set_title(\"Epochs vs Accuracy\")\n",
    "ax2.set_xlabel(\"Epochs\")\n",
    "ax2.set_ylabel(\"Loss\")\n",
    "ax2.set_title(\"Epochs vs Loss\")\n",
    "\n",
    "# Add legend\n",
    "plt.legend()\n",
    "\n",
    "plt.savefig(f\"Output/{dataset} - Model 4.png\", bbox_inches='tight', pad_inches=0)\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overhead Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = \"Overhead\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting Up Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('Data/train.csv', header=0).dropna()\n",
    "y_train_full = np.array(train['label'].values)\n",
    "X_train_full = train[[f'pixel{i}' for i in range(1, 784 + 1)]]\\\n",
    "                    .to_numpy()\n",
    "\n",
    "X_train, y_train = X_train_full[:-10000], y_train_full[:-10000]\n",
    "X_valid, y_valid = X_train_full[-10000:], y_train_full[-10000:]\n",
    "\n",
    "test = pd.read_csv('Data/test.csv', header=0).dropna()\n",
    "y_test = np.array(test['label'].values)\n",
    "X_test = test[[f'pixel{i}' for i in range(1, 784 + 1)]]\\\n",
    "                    .to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_valid, X_test = X_train / 255., X_valid / 255., X_test / 255."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = pd.read_csv('Data/classes.csv', header=0)['class'].values\n",
    "classes = list(classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Principal Component Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=28,\n",
    "          random_state=42)\n",
    "pca.fit(X_train)\n",
    "X_train = pca.transform(X_train)\n",
    "X_valid = pca.transform(X_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyper-Parameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans_per_k = [KMeans(n_clusters=k,\n",
    "                       init=\"k-means++\",\n",
    "                       max_iter=100,\n",
    "                       n_init=10,\n",
    "                       random_state=42)\\\n",
    "                        .fit(X_train)\n",
    "                    for k in range(50, 1000 + 1, 50)]\n",
    "\n",
    "inertias = [model.inertia_ for model in kmeans_per_k]\n",
    "\n",
    "plt.figure(figsize=(12,4))\n",
    "plt.plot([i for i in range(50, 1000 + 1, 50)],\n",
    "         inertias,\n",
    "         \"bo-\")\n",
    "plt.xlabel(\"$k$\")\n",
    "plt.ylabel(\"Inertia\")\n",
    "plt.title(\"Inertia vs $k$\")\n",
    "plt.savefig(f\"Output/{dataset} - Inertia.png\", bbox_inches='tight', pad_inches=0)\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 450\n",
    "kmeans = KMeans(n_clusters=k,\n",
    "                n_init=10,\n",
    "                init='k-means++',\n",
    "                random_state=42)\n",
    "kmeans.fit(X_train)\n",
    "cluster_distance = kmeans.transform(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLPs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "km_old_labels = kmeans.labels_\n",
    "closest = np.argmin(cluster_distance, axis = 0)\n",
    "labels = np.array([y_train[i] for i in closest])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(42)\n",
    "model1 = tf.keras.Sequential()\n",
    "model1.add(tf.keras.layers.InputLayer(shape=[28]))\n",
    "model1.add(tf.keras.layers.Flatten())\n",
    "model1.add(tf.keras.layers.Dense(300, activation=\"relu\"))\n",
    "model1.add(tf.keras.layers.Dense(100, activation=\"relu\"))\n",
    "model1.add(tf.keras.layers.Dense(10, activation=\"softmax\"))\n",
    "\n",
    "model1.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "               optimizer=\"sgd\",\n",
    "               metrics=[\"accuracy\"])\n",
    "\n",
    "history = model1.fit(X_train,\n",
    "                     y_train,\n",
    "                     epochs=15,\n",
    "                     verbose=0,\n",
    "                     validation_data=(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Plotting Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.840\n",
      "Loss: 0.898\n",
      "Loss: 0.710\n",
      "Loss: 0.693\n"
     ]
    }
   ],
   "source": [
    "train_loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "train_acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "epochs = list(range(1, len(train_loss) + 1))\n",
    "\n",
    "print(f'Loss: {train_loss[-1]:.3f}')\n",
    "print(f'Loss: {val_loss[-1]:.3f}')\n",
    "print(f'Loss: {train_acc[-1]:.3f}')\n",
    "print(f'Loss: {val_acc[-1]:.3f}')\n",
    "\n",
    "# Create a figure and two subplots\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 4))  # 1 row, 2 columns\n",
    "\n",
    "# Plot data on each subplot\n",
    "ax1.plot(epochs, train_acc, label=\"Training\")\n",
    "ax1.plot(epochs, val_acc, label=\"Validation\")\n",
    "ax2.plot(epochs, train_loss, label=\"Training\")\n",
    "ax2.plot(epochs, val_loss, label=\"Validation\")\n",
    "\n",
    "# Add labels and title\n",
    "ax1.set_xlabel(\"Epochs\")\n",
    "ax1.set_ylabel(\"Accuracy\")\n",
    "ax1.set_title(\"Epochs vs Accuracy\")\n",
    "ax2.set_xlabel(\"Epochs\")\n",
    "ax2.set_ylabel(\"Loss\")\n",
    "ax2.set_title(\"Epochs vs Loss\")\n",
    "\n",
    "# Add legend\n",
    "plt.legend()\n",
    "\n",
    "# Show the plot\n",
    "plt.savefig(f\"Output/{dataset} - Model 1.png\", bbox_inches='tight', pad_inches=0)\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_ri = np.array([X_train[i] for i in closest])\n",
    "y_train_ri = np.array([y_train[i] for i in closest])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(42)\n",
    "model2 = tf.keras.Sequential()\n",
    "model2.add(tf.keras.layers.InputLayer(shape=[28]))\n",
    "model2.add(tf.keras.layers.Flatten())\n",
    "model2.add(tf.keras.layers.Dense(300, activation=\"relu\"))\n",
    "model2.add(tf.keras.layers.Dense(100, activation=\"relu\"))\n",
    "model2.add(tf.keras.layers.Dense(10, activation=\"softmax\"))\n",
    "\n",
    "model2.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "               optimizer=\"sgd\",\n",
    "               metrics=[\"accuracy\"])\n",
    "\n",
    "history = model2.fit(X_train_ri, \n",
    "                     y_train_ri, \n",
    "                     epochs=15,\n",
    "                     verbose=0,\n",
    "                     validation_data=(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plotting Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 1.676\n",
      "Loss: 1.944\n",
      "Loss: 0.427\n",
      "Loss: 0.279\n"
     ]
    }
   ],
   "source": [
    "train_loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "train_acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "epochs = list(range(1, len(train_loss) + 1))\n",
    "\n",
    "print(f'Loss: {train_loss[-1]:.3f}')\n",
    "print(f'Loss: {val_loss[-1]:.3f}')\n",
    "print(f'Loss: {train_acc[-1]:.3f}')\n",
    "print(f'Loss: {val_acc[-1]:.3f}')\n",
    "\n",
    "# Create a figure and two subplots\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 4))  # 1 row, 2 columns\n",
    "\n",
    "# Plot data on each subplot\n",
    "ax1.plot(epochs, train_acc, label=\"Training Accuracy\")\n",
    "ax1.plot(epochs, val_acc, label=\"Validation Accuracy\")\n",
    "ax2.plot(epochs, train_loss, label=\"Training Loss\")\n",
    "ax2.plot(epochs, val_loss, label=\"Validation Loss\")\n",
    "\n",
    "# Add labels and title\n",
    "ax1.set_xlabel(\"Epochs\")\n",
    "ax1.set_ylabel(\"Accuracy\")\n",
    "ax1.set_title(\"Epochs vs Accuracy\")\n",
    "ax2.set_xlabel(\"Epochs\")\n",
    "ax2.set_ylabel(\"Loss\")\n",
    "ax2.set_title(\"Epochs vs Loss\")\n",
    "\n",
    "# Add legend\n",
    "plt.legend()\n",
    "\n",
    "plt.savefig(f\"Output/{dataset} - Model 2.png\", bbox_inches='tight', pad_inches=0)\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_fp = X_train\n",
    "y_train_fp = np.empty(len(X_train_fp), dtype=np.int32)\n",
    "for i in range(0,len(X_train_fp)):\n",
    "   y_train_fp[i] = labels[km_old_labels[i]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(42)\n",
    "model3 = tf.keras.Sequential()\n",
    "model3.add(tf.keras.layers.InputLayer(shape=[28]))\n",
    "model3.add(tf.keras.layers.Flatten())\n",
    "model3.add(tf.keras.layers.Dense(300, activation=\"relu\"))\n",
    "model3.add(tf.keras.layers.Dense(100, activation=\"relu\"))\n",
    "model3.add(tf.keras.layers.Dense(10, activation=\"softmax\"))\n",
    "\n",
    "model3.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "               optimizer=\"sgd\",\n",
    "               metrics=[\"accuracy\"])\n",
    "\n",
    "history = model3.fit(X_train_fp,\n",
    "                     y_train_fp,\n",
    "                     epochs=15,\n",
    "                     verbose=0,\n",
    "                     validation_data=(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plotting Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.707\n",
      "Loss: 2.587\n",
      "Loss: 0.727\n",
      "Loss: 0.373\n"
     ]
    }
   ],
   "source": [
    "train_loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "train_acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "epochs = list(range(1, len(train_loss) + 1))\n",
    "\n",
    "print(f'Loss: {train_loss[-1]:.3f}')\n",
    "print(f'Loss: {val_loss[-1]:.3f}')\n",
    "print(f'Loss: {train_acc[-1]:.3f}')\n",
    "print(f'Loss: {val_acc[-1]:.3f}')\n",
    "\n",
    "# Create a figure and two subplots\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 4))  # 1 row, 2 columns\n",
    "\n",
    "# Plot data on each subplot\n",
    "ax1.plot(epochs, train_acc, label=\"Training Accuracy\")\n",
    "ax1.plot(epochs, val_acc, label=\"Validation Accuracy\")\n",
    "ax2.plot(epochs, train_loss, label=\"Training Loss\")\n",
    "ax2.plot(epochs, val_loss, label=\"Validation Loss\")\n",
    "\n",
    "# Add labels and title\n",
    "ax1.set_xlabel(\"Epochs\")\n",
    "ax1.set_ylabel(\"Accuracy\")\n",
    "ax1.set_title(\"Epochs vs Accuracy\")\n",
    "ax2.set_xlabel(\"Epochs\")\n",
    "ax2.set_ylabel(\"Loss\")\n",
    "ax2.set_title(\"Epochs vs Loss\")\n",
    "\n",
    "# Add legend\n",
    "plt.legend()\n",
    "\n",
    "plt.savefig(f\"Output/{dataset} - Model 3.png\", bbox_inches='tight', pad_inches=0)\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_distances = cluster_distance[np.arange(len(X_train)), kmeans.labels_]\n",
    "for i in range(k):\n",
    "    in_cluster = (kmeans.labels_ == i)\n",
    "    cluster_dist = X_distances[in_cluster]\n",
    "    cutoff = np.percentile(cluster_dist, 20)\n",
    "    above_cutoff = (X_distances > cutoff)\n",
    "    X_distances[in_cluster & above_cutoff] = -1\n",
    "\n",
    "pp = (X_distances != -1)\n",
    "X_train_pp = X_train[pp]\n",
    "y_train_pp = y_train_fp[pp]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(42)\n",
    "model4 = tf.keras.Sequential()\n",
    "model4.add(tf.keras.layers.InputLayer(shape=[28]))\n",
    "model4.add(tf.keras.layers.Flatten())\n",
    "model4.add(tf.keras.layers.Dense(300, activation=\"relu\"))\n",
    "model4.add(tf.keras.layers.Dense(100, activation=\"relu\"))\n",
    "model4.add(tf.keras.layers.Dense(10, activation=\"softmax\"))\n",
    "\n",
    "model4.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "               optimizer=\"sgd\",\n",
    "               metrics=[\"accuracy\"])\n",
    "\n",
    "history = model4.fit(X_train_pp,\n",
    "                     y_train_pp, \n",
    "                     epochs=15,\n",
    "                     verbose=0,\n",
    "                     validation_data=(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plotting Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.844\n",
      "Loss: 1.943\n",
      "Loss: 0.680\n",
      "Loss: 0.386\n"
     ]
    }
   ],
   "source": [
    "train_loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "train_acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "epochs = list(range(1, len(train_loss) + 1))\n",
    "\n",
    "print(f'Loss: {train_loss[-1]:.3f}')\n",
    "print(f'Loss: {val_loss[-1]:.3f}')\n",
    "print(f'Loss: {train_acc[-1]:.3f}')\n",
    "print(f'Loss: {val_acc[-1]:.3f}')\n",
    "\n",
    "# Create a figure and two subplots\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 4))  # 1 row, 2 columns\n",
    "\n",
    "# Plot data on each subplot\n",
    "ax1.plot(epochs, train_acc, label=\"Training Accuracy\")\n",
    "ax1.plot(epochs, val_acc, label=\"Validation Accuracy\")\n",
    "ax2.plot(epochs, train_loss, label=\"Training Loss\")\n",
    "ax2.plot(epochs, val_loss, label=\"Validation Loss\")\n",
    "\n",
    "# Add labels and title\n",
    "ax1.set_xlabel(\"Epochs\")\n",
    "ax1.set_ylabel(\"Accuracy\")\n",
    "ax1.set_title(\"Epochs vs Accuracy\")\n",
    "ax2.set_xlabel(\"Epochs\")\n",
    "ax2.set_ylabel(\"Loss\")\n",
    "ax2.set_title(\"Epochs vs Loss\")\n",
    "\n",
    "# Add legend\n",
    "plt.legend()\n",
    "\n",
    "plt.savefig(f\"Output/{dataset} - Model 4.png\", bbox_inches='tight', pad_inches=0)\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
