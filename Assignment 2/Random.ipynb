{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import progressbar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"Data\"\n",
    "files = [\n",
    "    \"docword.kos.txt\",\n",
    "    \"docword.nips.txt\",\n",
    "    \"docword.enron.txt\",\n",
    "    ]\n",
    "max_k = 15\n",
    "k_iters = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def npify(indices:set|list,\n",
    "          arr_len:int):\n",
    "    arr = np.zeros(arr_len)\n",
    "    for index in indices:\n",
    "        arr[index - 1] = 1\n",
    "    return arr\n",
    "\n",
    "\n",
    "def setify(arr):\n",
    "    threshold = 0.5 * np.max(arr)\n",
    "    indices = []\n",
    "    for i in range(len(arr)):\n",
    "        if arr[i] >= threshold:\n",
    "            indices.append(i)\n",
    "    return set(indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def jac_dist(v1:set,\n",
    "             v2:set):    \n",
    "    union = len(v1.union(v2))\n",
    "    intersection = len(v1.intersection(v2))\n",
    "    \n",
    "    if union == 0:\n",
    "        return 1\n",
    "    \n",
    "    jacc_dist = 1 - (intersection / union)\n",
    "    return jacc_dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_inertia(data,\n",
    "                 cluster_labels,\n",
    "                 centroids):\n",
    "    inertia = 0\n",
    "    \n",
    "    for i in range(len(data)):\n",
    "        inertia += jac_dist(\n",
    "            data[i],\n",
    "            centroids[cluster_labels[i]]\n",
    "            )\n",
    "    \n",
    "    return inertia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_kmeans(data:list,\n",
    "                  k:int,\n",
    "                  dim:int,\n",
    "                  max_iter=30,\n",
    "                  past_centroids:list=None):\n",
    "    \"\"\"\n",
    "    Custom K-Means implementation with a Jaccard Similarity Measure.\n",
    "\n",
    "    Args:\n",
    "        data: \n",
    "        k: The desired number of clusters.\n",
    "        max_iter: Maximum number of iterations (default: 30).\n",
    "\n",
    "    Returns:\n",
    "        A tuple containing:\n",
    "            cluster_labels: An array of cluster labels for each data point.\n",
    "            centroids: The final centroids (cluster centers) after convergence.\n",
    "            intertia: The inertia for the final centroids and clusters\n",
    "    \"\"\"    \n",
    "    # Initialize centroids randomly\n",
    "    rnd = np.random.choice(a=len(data),\n",
    "                               size=k,\n",
    "                               replace=False)\n",
    "    centroids = []\n",
    "    for i in range(k):\n",
    "        centroids.append(data[rnd[i]])\n",
    "\n",
    "    # Iterate for max_iter or until convergence\n",
    "    cluster_labels = []\n",
    "    mean_calc = [[0, np.zeros(dim)]] * len(centroids)\n",
    "    for _ in range(max_iter):\n",
    "        old_centroids = centroids.copy()\n",
    "\n",
    "        # Assign data points to closest centroids\n",
    "        for i in range(len(data)):\n",
    "            new_cluster = 0\n",
    "            for j in range(len(centroids)):\n",
    "                if jac_dist(data[i], centroids[new_cluster]) \\\n",
    "                    > jac_dist(data[i], centroids[j]):\n",
    "                    new_cluster = j\n",
    "            \n",
    "            cluster_labels.append(new_cluster)\n",
    "            mean_calc[new_cluster] = [mean_calc[new_cluster][0] + 1,\n",
    "                                      mean_calc[new_cluster][1] + npify(data[i], dim)]\n",
    "                \n",
    "        # Update centroids (mean of assigned points)\n",
    "        centroids = []\n",
    "        for cl in mean_calc:\n",
    "            if cl[0] == 0:\n",
    "                centroids.append(setify(cl[1]))\n",
    "            else:    \n",
    "                centroids.append(setify(cl[1] / cl[0]))\n",
    "\n",
    "        # Check for convergence\n",
    "        if np.all(np.array([jac_dist(c, oc)\n",
    "                            for c in centroids\n",
    "                            for oc in old_centroids]) < 1e-3):\n",
    "            break\n",
    "    \n",
    "    # Update clustering after centroids have been updated\n",
    "    for i in range(len(data)):\n",
    "        new_cluster = 0\n",
    "        \n",
    "        for j in range(len(centroids)):\n",
    "            if jac_dist(data[i], centroids[new_cluster]) \\\n",
    "                > jac_dist(data[i], centroids[j]):\n",
    "                new_cluster = j\n",
    "        \n",
    "        cluster_labels.append(new_cluster)\n",
    "    \n",
    "    # Calculate Inertia            \n",
    "    inertia = calc_inertia(\n",
    "                data=data,\n",
    "                cluster_labels=cluster_labels,\n",
    "                centroids=centroids\n",
    "                )\n",
    "\n",
    "    return cluster_labels, centroids, inertia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kmeans_pipeline(file:str,\n",
    "                    max_k:int,\n",
    "                    k_iters:int):\n",
    "    \n",
    "    source = open(f'{file_path}/{file}', 'r')\n",
    "    D = int(next(source).strip())\n",
    "    W = int(next(source).strip())\n",
    "    NNZ = int(next(source).strip())\n",
    "    data = []\n",
    "\n",
    "    tmp = None\n",
    "    for line in source:\n",
    "        d, w, _ = list(map(int, line.strip().split()))\n",
    "        if d > len(data):\n",
    "            if tmp is not None:\n",
    "                data.append(set(tmp))\n",
    "            tmp = [w]\n",
    "        else:\n",
    "            tmp.append(w)\n",
    "    data.append(set(tmp))\n",
    "\n",
    "    # Sanity Check\n",
    "    read_words = sum([len(doc) for doc in data])\n",
    "    if read_words != NNZ:\n",
    "        return \"Failure: Data Read Improperly\"\n",
    "    \n",
    "    file_name = file.split('.')[1].upper()\n",
    "    \n",
    "    widgets = [f'Clustering on {file_name}: ', progressbar.Percentage(), ' | ',\n",
    "            progressbar.Timer(), ' | (', progressbar.ETA(), ') ']\n",
    "    bar = progressbar.ProgressBar(\n",
    "        maxval=(max_k - 1),\n",
    "        widgets=widgets)\\\n",
    "            .start()\n",
    "    \n",
    "    k_inertia = []\n",
    "    past_centroids = None\n",
    "    for k in range(2, max_k + 1):\n",
    "        min_inertia = 10 ** 6\n",
    "        \n",
    "        if k == 2:\n",
    "            for _ in range(k_iters):\n",
    "                cluster_labels, centroids, inertia = \\\n",
    "                    custom_kmeans(\n",
    "                        data=data,\n",
    "                        k=k,\n",
    "                        dim=W\n",
    "                        )\n",
    "\n",
    "                if min_inertia > inertia:\n",
    "                    min_inertia = inertia\n",
    "                    past_centroids = centroids\n",
    "        else:\n",
    "            flag = True\n",
    "            counter = 0\n",
    "            while flag:\n",
    "                cluster_labels, centroids, inertia = \\\n",
    "                    custom_kmeans(\n",
    "                        data=data,\n",
    "                        k=k,\n",
    "                        dim=W,\n",
    "                        )\n",
    "                if min_inertia > inertia:\n",
    "                    min_inertia = inertia\n",
    "                    min_centroids = centroids\n",
    "                \n",
    "                if min_inertia <= k_inertia[-1]:\n",
    "                    flag = False\n",
    "                \n",
    "                counter += 1\n",
    "                if counter > k_iters:\n",
    "                    flag = False\n",
    "        \n",
    "        bar.update(k - 2 + 1)\n",
    "        k_inertia.append(min_inertia)\n",
    "    \n",
    "    print(f'Sparsity of Matrix on {file_name}: {NNZ / (D * W) * 100:.3f} %')\n",
    "    print()\n",
    "    \n",
    "    return k_inertia            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clustering on KOS: 100% | Elapsed Time: 0:04:06 | (ETA:  0:00:00)              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sparsity of Matrix on KOS: 1.491 %\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clustering on NIPS: 100% | Elapsed Time: 0:07:10 | (ETA:  0:00:00)             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sparsity of Matrix on NIPS: 4.006 %\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clustering on ENRON: 100% | Elapsed Time: 1:05:02 | (ETA:  0:00:00)            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sparsity of Matrix on ENRON: 0.331 %\n",
      "\n"
     ]
    }
   ],
   "source": [
    "logs = []\n",
    "for file in files:\n",
    "    k_inertia = kmeans_pipeline(\n",
    "                    file=file,\n",
    "                    max_k=max_k,\n",
    "                    k_iters=k_iters)\n",
    "    \n",
    "    file_name = file.split('.')[1].upper()\n",
    "    logs.append((file_name, k_inertia))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "for log in logs:\n",
    "    file_name = log[0]\n",
    "    k_inertia = log[1]\n",
    "    plt.figure(figsize=(10, 4))\n",
    "    plt.plot(list(range(2, max_k + 1)),\n",
    "             k_inertia,\n",
    "             marker='o', \n",
    "             linestyle='-')\n",
    "    plt.title(f'Clustering on {file_name}')\n",
    "    plt.xlabel('K')\n",
    "    plt.ylabel('Inertia (Jaccard Similarity)')\n",
    "    plt.ylim([max(min(k_inertia) - 0.01 * max(k_inertia), 0), 1.01 * max(k_inertia)])\n",
    "    plt.savefig(f'Output/Random/{file_name}.png')\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dmml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.1.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
